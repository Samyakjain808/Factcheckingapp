import json
import fitz
import streamlit as st

from claim_extractor import extract_claims
from verifier import verify_claim

st.set_page_config(page_title="AI Fact Checker", layout="wide")

st.title("ğŸ§  AI Fact-Checking Web App")
st.write("Upload a PDF. Claims will be extracted and verified using live web data.")

uploaded_file = st.file_uploader("Upload PDF", type=["pdf"])

def extract_text_from_pdf(file):
    doc = fitz.open(stream=file.read(), filetype="pdf")
    return "\n".join(page.get_text() for page in doc)

if uploaded_file:
    with st.spinner("ğŸ“„ Extracting text from PDF..."):
        pdf_text = extract_text_from_pdf(uploaded_file)

    with st.spinner("ğŸ” Extracting claims..."):
        raw = extract_claims(pdf_text)
        try:
            claims = json.loads(raw)
        except json.JSONDecodeError:
            st.error("Failed to parse claims.")
            claims = []

    if not claims:
        st.warning("No verifiable claims found.")
    else:
        st.subheader(f"Found {len(claims)} claims")

        for i, c in enumerate(claims, 1):
            st.markdown(f"### Claim {i}")
            st.write(c["claim"])

            with st.spinner("ğŸŒ Verifying with live web data..."):
                result = verify_claim(c["claim"])

            status = result.get("status", "Unknown")

            if status == "Verified":
                st.success("âœ… Verified")
            elif status == "Inaccurate":
                st.warning("âš ï¸ Inaccurate")
            elif status == "False":
                st.error("âŒ False")
            else:
                st.info("â“ Unknown")

            st.write(result.get("explanation", ""))
            st.divider()
